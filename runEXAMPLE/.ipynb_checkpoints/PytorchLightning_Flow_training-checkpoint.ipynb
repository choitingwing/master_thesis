{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75e2c63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "#import\n",
    "import datasets\n",
    "from toolbox import load_file, find_68_interval, models_dir\n",
    "from constants import run_version, dataset_name, datapath, data_filename, label_filename, plots_dir, project_name, n_files, n_files_val, dataset_em, dataset_noise, test_file_ids, train_data_points, val_data_points, norm, epochs\n",
    "from generator import Prepare_Dataset\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import argparse\n",
    "from termcolor import colored\n",
    "import time\n",
    "from radiotools import helper as hp\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torchviz import make_dot\n",
    "#--------------------------------------------\n",
    "# some constants\n",
    "architectures_dir = \"architectures\"\n",
    "learning_rate = 0.00005\n",
    "es_patience = 8\n",
    "es_min_delta = 0.0001 # Old value: es_min_delta = 0.0001\n",
    "batchSize = 64\n",
    "# ---------------------\n",
    "epochs = 10\n",
    "norm = 1e-6\n",
    "train_data_points = 99900 #190000\n",
    "val_data_points = 25000   #25000\n",
    "test_data_points = 99900  #20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb768711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parse arguments\n",
    "# parser = argparse.ArgumentParser(description='Neural network for neutrino energy reconstruction')\n",
    "# parser.add_argument(\"run_id\", type=str ,help=\"the id of the run, eg '3.2' for run3.2\")\n",
    "# args = parser.parse_args()\n",
    "# run_id = args.run_id\n",
    "run_id = \"Model.5\"\n",
    "# Save the run name\n",
    "run_name = f\"run{run_id}\"\n",
    "# Make sure run_name is compatible with run_version\n",
    "this_run_version = run_name.split(\".\")[0]\n",
    "this_run_id = run_name.split(\".\")[1]\n",
    "assert this_run_version == run_version, f\"run_version ({run_version}) does not match the run version for this run ({this_run_version})\"\n",
    "\n",
    "# Models folder\n",
    "saved_model_dir = models_dir(run_name)\n",
    "# Make sure saved_models folder exists\n",
    "if not os.path.exists(saved_model_dir):\n",
    "    os.makedirs(saved_model_dir)\n",
    "# Make sure architectures folder exists\n",
    "if not os.path.exists(f\"{saved_model_dir}/{architectures_dir}\"):\n",
    "    os.makedirs(f\"{saved_model_dir}/{architectures_dir}\")\n",
    "# Make sure plot dir exists\n",
    "plots_dir=f\"{plots_dir}/{run_id}\"\n",
    "if not os.path.exists(plots_dir):\n",
    "    os.makedirs(plots_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d8bd700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "datapath =  /mnt/md0/data/SouthPole/single_surface_4LPDA_PA_15m_RNOG_fullsim.json/ARZ2020_emhad_noise.yaml/G03generate_events_full_surface_sim/LPDA_2of4_100Hz/4LPDA_1dipole_fullband/em_had_separately/\n",
      "data_filename =  data_had_emhad_1-3_had_1_LPDA_2of4_100Hz_4LPDA_1dipole_fullband_\n",
      "label_filename =  labels_had_emhad_1-3_had_1_LPDA_2of4_100Hz_4LPDA_1dipole_fullband_\n",
      "\n",
      "Training files #:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32]\n",
      "Val files #:  [33 34 35 36 37]\n",
      "Test files #:  [38 39 40]\n"
     ]
    }
   ],
   "source": [
    "# Info for dataset\n",
    "print(\"\\ndatapath = \",datapath)\n",
    "print(\"data_filename = \", data_filename)\n",
    "print(\"label_filename = \", label_filename)\n",
    "\n",
    "n_files_test = 3\n",
    "n_files_train = n_files - n_files_val - n_files_test\n",
    "\n",
    "list_of_file_ids_train = np.arange(n_files_train, dtype=int)\n",
    "list_of_file_ids_val = np.arange(n_files_train, n_files_train + n_files_val, dtype=int)#np.int?\n",
    "list_of_file_ids_test = np.arange(n_files_train + n_files_val, n_files, dtype=int)\n",
    "n_events_per_file = 100000\n",
    "\n",
    "print(\"\\nTraining files #: \",list_of_file_ids_train)\n",
    "print(\"Val files #: \",list_of_file_ids_val)\n",
    "print(\"Test files #: \",list_of_file_ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c618af73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing datasets...\n",
      "Picked training set ids: [29]\n",
      "Picked val set ids: [37]\n",
      "loading file 29\n",
      "finished loading file 29 in 38.5605993270874s\n",
      "Total train data points:  99999\n",
      "loading file 37\n",
      "finished loading file 37 in 9.914751052856445s\n",
      "Total train data points:  99995\n"
     ]
    }
   ],
   "source": [
    "# dataset\n",
    "print(\"\\nPreparing datasets...\")\n",
    "\n",
    "list_of_file_ids_train_small = np.random.choice(list_of_file_ids_train, size=33, replace=False)\n",
    "print(\"Picked training set ids:\",list_of_file_ids_train_small)\n",
    "list_of_file_ids_val_small = np.random.choice(list_of_file_ids_val, size=1, replace=False)\n",
    "print(\"Picked val set ids:\",list_of_file_ids_val_small)\n",
    "\n",
    "train = Prepare_Dataset(file_ids=list_of_file_ids_train_small,points = 3290000)\n",
    "val = Prepare_Dataset(file_ids=list_of_file_ids_val_small, points = val_data_points)\n",
    "\n",
    "# x_train, y_train = train[0]\n",
    "# x_val, y_val = val[0]\n",
    "\n",
    "# print(train, len(train), x_train.shape, y_train)\n",
    "# print(val, len(val), x_val.shape, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc25c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file 29\n",
      "finished loading file 29 in 9.800905704498291s\n",
      "loading file 1\n",
      "finished loading file 1 in 58.06258773803711s\n",
      "loading file 11\n",
      "finished loading file 11 in 63.70002222061157s\n",
      "loading file 23\n",
      "finished loading file 23 in 54.78714919090271s\n",
      "loading file 18\n",
      "finished loading file 18 in 56.996856927871704s\n",
      "loading file 3\n",
      "finished loading file 3 in 50.06057047843933s\n",
      "loading file 10\n",
      "finished loading file 10 in 62.67910718917847s\n",
      "loading file 0\n",
      "finished loading file 0 in 50.74393677711487s\n",
      "loading file 5\n",
      "finished loading file 5 in 108.92739772796631s\n",
      "loading file 17\n",
      "finished loading file 17 in 53.90181064605713s\n",
      "loading file 20\n",
      "finished loading file 20 in 45.3966748714447s\n",
      "loading file 26\n",
      "finished loading file 26 in 44.7163143157959s\n",
      "loading file 7\n",
      "finished loading file 7 in 43.39485430717468s\n",
      "loading file 16\n",
      "finished loading file 16 in 63.26037621498108s\n",
      "loading file 24\n",
      "finished loading file 24 in 60.04666757583618s\n",
      "loading file 27\n",
      "finished loading file 27 in 36.70982646942139s\n",
      "loading file 8\n",
      "finished loading file 8 in 34.99137091636658s\n",
      "loading file 9\n",
      "finished loading file 9 in 19.713388919830322s\n",
      "loading file 25\n",
      "finished loading file 25 in 35.9482638835907s\n",
      "loading file 30\n",
      "finished loading file 30 in 35.97974634170532s\n",
      "loading file 28\n",
      "finished loading file 28 in 35.873133420944214s\n",
      "loading file 21\n",
      "finished loading file 21 in 35.34647727012634s\n",
      "loading file 14\n",
      "finished loading file 14 in 36.46565318107605s\n"
     ]
    }
   ],
   "source": [
    "list_of_file_ids_train_small = np.random.choice(list_of_file_ids_train, size=33, replace=False)\n",
    "train = Prepare_Dataset(file_ids=list_of_file_ids_train_small,points = 3290000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1411a6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_point = []\n",
    "for x, y in train:\n",
    "    total_train_point.append(y.item())\n",
    "total_train_point_list = np.array(total_train_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c429af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from radiotools import plthelpers as php\n",
    "fig, ax = php.get_histogram(total_train_point_list, bins=np.linspace(15.5, 20, 45),  xlabel=\"True Energy\")\n",
    "plt.title(f\"True Energy(Train data set, ARZ) for {run_name} \")\n",
    "# fig.savefig(f\"{plots_dir}/energy_resolution_{run_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6bbc38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(train, batch_size=batchSize, shuffle=True, num_workers=64)\n",
    "val_loader = DataLoader(val, batch_size=batchSize, shuffle=False, num_workers=64)\n",
    "                               \n",
    "# x, y = next(iter(train_loader))\n",
    "# print(f\"Feature batch shape: {x.size()}\")\n",
    "# print(f\"Labels batch shape: {y.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a3a7ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model params\n",
    "conv2D_filter_size = 5\n",
    "pooling_size = 4\n",
    "amount_Conv2D_layers_per_block = 3 \n",
    "amount_Conv2D_blocks = 4\n",
    "conv2D_filter_amount = 32\n",
    "\n",
    "criterion = obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a3264bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "E_Model(\n",
       "  (cnn0): Conv2d(1, 32, kernel_size=(1, 5), stride=(1, 1), padding=same)\n",
       "  (cnn1): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1), padding=same)\n",
       "  (cnn2_1): Conv2d(32, 64, kernel_size=(1, 5), stride=(1, 1), padding=same)\n",
       "  (cnn2_2): Conv2d(64, 64, kernel_size=(1, 5), stride=(1, 1), padding=same)\n",
       "  (cnn3_1): Conv2d(64, 128, kernel_size=(1, 5), stride=(1, 1), padding=same)\n",
       "  (cnn3_2): Conv2d(128, 128, kernel_size=(1, 5), stride=(1, 1), padding=same)\n",
       "  (cnn4_1): Conv2d(128, 256, kernel_size=(1, 5), stride=(1, 1), padding=same)\n",
       "  (cnn4_2): Conv2d(256, 256, kernel_size=(1, 5), stride=(1, 1), padding=same)\n",
       "  (avgpool): AvgPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0)\n",
       "  (bn1): BatchNorm2d(256, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "  (pdf): pdf(\n",
       "    (layer_list): ModuleList(\n",
       "      (0): ModuleList(\n",
       "        (0): gf_block()\n",
       "        (1): gf_block()\n",
       "      )\n",
       "    )\n",
       "    (mlp_predictors): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=2560, out_features=512, bias=True)\n",
       "        (1): Tanh()\n",
       "        (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (3): Tanh()\n",
       "        (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (5): Tanh()\n",
       "        (6): Linear(in_features=128, out_features=63, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create model using Pytorch Lightning \n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau \n",
    "import pytorch_lightning as pl\n",
    "from torchsummary import summary\n",
    "import jammy_flows\n",
    "\n",
    "class E_Model(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn0 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(1, conv2D_filter_size), padding='same')\n",
    "        self.cnn1 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(1, conv2D_filter_size), padding='same')\n",
    "        \n",
    "        self.cnn2_1 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1, conv2D_filter_size), padding='same')\n",
    "        self.cnn2_2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(1, conv2D_filter_size), padding='same')\n",
    "\n",
    "        self.cnn3_1 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(1, conv2D_filter_size), padding='same')\n",
    "        self.cnn3_2 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(1, conv2D_filter_size), padding='same')\n",
    "        \n",
    "        self.cnn4_1 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(1, conv2D_filter_size), padding='same')\n",
    "        self.cnn4_2 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(1, conv2D_filter_size), padding='same')\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=(1, pooling_size))\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(256, eps = 0.001, momentum = 0.99, affine=True)\n",
    "#         self.pdf = jammy_flows.pdf(\"e1\", \"gg\", conditional_input_dim=2560, hidden_mlp_dims_sub_pdfs=\"1024-1024-512-256-128\")\n",
    "        self.pdf = jammy_flows.pdf(\"e1\", \"gg\", conditional_input_dim=2560, hidden_mlp_dims_sub_pdfs=\"512-256-128\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn0(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.cnn1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.cnn1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.avgpool(x)\n",
    "        \n",
    "        x = self.cnn2_1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.cnn2_2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.cnn2_2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.avgpool(x)\n",
    "        \n",
    "        x = self.cnn3_1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.cnn3_2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.cnn3_2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.avgpool(x)\n",
    "        \n",
    "        x = self.cnn4_1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.cnn4_2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.cnn4_2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.avgpool(x)\n",
    "        \n",
    "        x = self.bn1(x)\n",
    "        out =  torch.flatten(x, 1) #x.view(-1,2560) # torch.flatten(x, 1) ##\n",
    "        return out\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate, eps=1e-7) \n",
    "        scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.2, patience=es_patience-3, min_lr=0.000001, verbose=1)\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': scheduler, 'monitor': 'val_loss'}\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y = train_batch\n",
    "        conv_out = self.forward(x)\n",
    "#         print(torch.max(conv_out),torch.min(conv_out))\n",
    "        log_pdf, _,_= self.pdf(y, conditional_input=conv_out)\n",
    "        loss=-log_pdf.mean()\n",
    "        self.log('train_loss', loss, prog_bar=True, on_epoch=True, logger=True, on_step=False)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y = val_batch\n",
    "        conv_out = self.forward(x)\n",
    "        log_pdf, _,_= self.pdf(y, conditional_input=conv_out)\n",
    "        loss=-log_pdf.mean()\n",
    "        self.log('val_loss', loss, prog_bar=True, on_epoch = True, logger=True)\n",
    "\n",
    "# create a model\n",
    "model = E_Model()\n",
    "model.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6fca939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 5, 512]             192\n",
      "            Conv2d-2           [-1, 32, 5, 512]           5,152\n",
      "            Conv2d-3           [-1, 32, 5, 512]           5,152\n",
      "         AvgPool2d-4           [-1, 32, 5, 128]               0\n",
      "            Conv2d-5           [-1, 64, 5, 128]          10,304\n",
      "            Conv2d-6           [-1, 64, 5, 128]          20,544\n",
      "            Conv2d-7           [-1, 64, 5, 128]          20,544\n",
      "         AvgPool2d-8            [-1, 64, 5, 32]               0\n",
      "            Conv2d-9           [-1, 128, 5, 32]          41,088\n",
      "           Conv2d-10           [-1, 128, 5, 32]          82,048\n",
      "           Conv2d-11           [-1, 128, 5, 32]          82,048\n",
      "        AvgPool2d-12            [-1, 128, 5, 8]               0\n",
      "           Conv2d-13            [-1, 256, 5, 8]         164,096\n",
      "           Conv2d-14            [-1, 256, 5, 8]         327,936\n",
      "           Conv2d-15            [-1, 256, 5, 8]         327,936\n",
      "        AvgPool2d-16            [-1, 256, 5, 2]               0\n",
      "      BatchNorm2d-17            [-1, 256, 5, 2]             512\n",
      "================================================================\n",
      "Total params: 1,087,552\n",
      "Trainable params: 1,087,552\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 3.83\n",
      "Params size (MB): 4.15\n",
      "Estimated Total Size (MB): 7.99\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "os.system(f\"python print_model.py\")\n",
    "# Sleep for a few seconds to free up some resources...\n",
    "time.sleep(1)\n",
    "\n",
    "#  x, y = next(iter(train_loader))\n",
    "#  model.pdf.init_params(data=y)\n",
    "\n",
    "# def weights_init(m):\n",
    "#     if isinstance(m, nn.Conv2d):\n",
    "#         nn.init.xavier_uniform_(m.weight.data)\n",
    "#         torch.nn.init.zeros_(m.bias.data)\n",
    "#     if isinstance(m, nn.Linear):\n",
    "#         nn.init.xavier_uniform_(m.weight.data)\n",
    "#         torch.nn.init.zeros_(m.bias.data)\n",
    "# model.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15779bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#callback\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import DeviceStatsMonitor\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "\n",
    "mc = ModelCheckpoint(dirpath=saved_model_dir, filename= \"latest_model_checkpoint\", \n",
    "    monitor='val_loss', verbose=1)\n",
    "\n",
    "es = EarlyStopping(\"val_loss\", patience=es_patience, min_delta=es_min_delta, verbose=1)\n",
    "\n",
    "class MyPrintingCallback(Callback):\n",
    "    def on_train_start(self, trainer, pl_module):\n",
    "        print(\"Training is starting\")\n",
    "#         x, y = next(iter(train_loader))\n",
    "#         model.pdf.init_params(data=y)\n",
    "    \n",
    "callbacks = [es, mc, MyPrintingCallback()] # DeviceStatsMonitor()\n",
    "\n",
    "# Configuring CSV-logger : save epoch and loss values\n",
    "csv_logger = CSVLogger(saved_model_dir, version=0)#, flush_logs_every_n_steps=64)#, append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fad342d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto select gpus: [0]\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1, \n",
    "    auto_select_gpus=True,\n",
    "#     accelerator=\"gpu\", \n",
    "#     devices=[2],\n",
    "    callbacks = callbacks, \n",
    "    max_epochs = epochs,\n",
    "    logger = csv_logger,\n",
    "    precision = 32,\n",
    "    num_sanity_val_steps=0\n",
    "    )\n",
    "    # profiler=\"simple\",#how long a function takes or how much memory is used.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad3b8a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "   | Name    | Type        | Params\n",
      "-----------------------------------------\n",
      "0  | cnn0    | Conv2d      | 192   \n",
      "1  | cnn1    | Conv2d      | 5.2 K \n",
      "2  | cnn2_1  | Conv2d      | 10.3 K\n",
      "3  | cnn2_2  | Conv2d      | 20.5 K\n",
      "4  | cnn3_1  | Conv2d      | 41.1 K\n",
      "5  | cnn3_2  | Conv2d      | 82.0 K\n",
      "6  | cnn4_1  | Conv2d      | 164 K \n",
      "7  | cnn4_2  | Conv2d      | 327 K \n",
      "8  | avgpool | AvgPool2d   | 0     \n",
      "9  | bn1     | BatchNorm2d | 512   \n",
      "10 | pdf     | pdf         | 1.5 M \n",
      "-----------------------------------------\n",
      "2.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 M     Total params\n",
      "8.542     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is starting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25ccace92297414f8e884803393827c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/distributions/normal.py:85: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /home/ting/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646756402876/work/aten/src/ATen/native/cuda/jit_utils.cpp:860.)\n",
      "  return self.loc + self.scale * torch.erfinv(2 * value - 1) * math.sqrt(2)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "   | Name    | Type        | Params\n",
      "-----------------------------------------\n",
      "0  | cnn0    | Conv2d      | 192   \n",
      "1  | cnn1    | Conv2d      | 5.2 K \n",
      "2  | cnn2_1  | Conv2d      | 10.3 K\n",
      "3  | cnn2_2  | Conv2d      | 20.5 K\n",
      "4  | cnn3_1  | Conv2d      | 41.1 K\n",
      "5  | cnn3_2  | Conv2d      | 82.0 K\n",
      "6  | cnn4_1  | Conv2d      | 164 K \n",
      "7  | cnn4_2  | Conv2d      | 327 K \n",
      "8  | avgpool | AvgPool2d   | 0     \n",
      "9  | bn1     | BatchNorm2d | 512   \n",
      "10 | pdf     | pdf         | 1.5 M \n",
      "-----------------------------------------\n",
      "2.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 M     Total params\n",
      "8.542     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is starting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2632975f7dcd4d6a9276e00560155bde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "except: \n",
    "    trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6e3cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model (for opening in eg Netron)\n",
    "save_model_path=os.path.join(saved_model_dir, f\"{run_name}.pt\")\n",
    "torch.save(model.state_dict(), save_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b0becd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
