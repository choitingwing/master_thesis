{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda . GPU # is 0\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from radiotools import plthelpers as php\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os\n",
    "import time\n",
    "from radiotools import helper as hp\n",
    "from NuRadioReco.utilities import units\n",
    "import pickle\n",
    "import argparse\n",
    "from termcolor import colored\n",
    "from toolbox import load_file, models_dir\n",
    "from constants import datapath, data_filename, label_filename, test_file_ids\n",
    "# -------\n",
    "#GPU\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using\",device,\". GPU # is\",torch.cuda.current_device())\n",
    "\n",
    "# # Parse arguments\n",
    "# parser = argparse.ArgumentParser(description='Evaluate energy resolution')\n",
    "# parser.add_argument(\"run_id\", type=str ,help=\"the id of the run, eg '3.2' for run3.2\")\n",
    "\n",
    "# args = parser.parse_args()\n",
    "# run_id = args.run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mEvaluating energy resolution for runModel.3...\u001b[0m\n",
      "../common/models/runModel.3\n"
     ]
    }
   ],
   "source": [
    "run_id = \"Model.3\"\n",
    "# Save the run name and filename\n",
    "run_name = f\"run{run_id}\"\n",
    "filename = f\"model_history_log_{run_name}.csv\"\n",
    "\n",
    "# Models folder\n",
    "saved_model_dir = models_dir(run_name)\n",
    "\n",
    "print(colored(f\"Evaluating energy resolution for {run_name}...\", \"yellow\"))\n",
    "print(saved_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "E_Model(\n",
       "  (cnn0): Conv2d(1, 32, kernel_size=(1, 5), stride=(1, 1), padding=same)\n",
       "  (cnn1): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1), padding=same)\n",
       "  (cnn2_1): Conv2d(32, 64, kernel_size=(1, 5), stride=(1, 1), padding=same)\n",
       "  (cnn2_2): Conv2d(64, 64, kernel_size=(1, 5), stride=(1, 1), padding=same)\n",
       "  (cnn3_1): Conv2d(64, 128, kernel_size=(1, 5), stride=(1, 1), padding=same)\n",
       "  (cnn3_2): Conv2d(128, 128, kernel_size=(1, 5), stride=(1, 1), padding=same)\n",
       "  (cnn4_1): Conv2d(128, 256, kernel_size=(1, 5), stride=(1, 1), padding=same)\n",
       "  (cnn4_2): Conv2d(256, 256, kernel_size=(1, 5), stride=(1, 1), padding=same)\n",
       "  (avgpool): AvgPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0)\n",
       "  (bn1): BatchNorm2d(256, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "  (pdf): pdf(\n",
       "    (layer_list): ModuleList(\n",
       "      (0): ModuleList(\n",
       "        (0): gf_block()\n",
       "        (1): gf_block()\n",
       "      )\n",
       "    )\n",
       "    (mlp_predictors): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=2560, out_features=128, bias=True)\n",
       "        (1): Tanh()\n",
       "        (2): Linear(in_features=128, out_features=63, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "from generator import E_Model\n",
    "import pytorch_lightning as pl\n",
    "import jammy_flows\n",
    "\n",
    "# mymodel = E_Model().to(device)\n",
    "mymodel = E_Model()\n",
    "save_model_path=os.path.join(saved_model_dir,  \"latest_model_checkpoint.ckpt\")\n",
    "mymodel = E_Model().load_from_checkpoint(save_model_path)\n",
    "\n",
    "# save_model_path=os.path.join(saved_model_dir,  f\"{run_name}.pt\")\n",
    "# mymodel.load_state_dict(torch.load(save_model_path))\n",
    "mymodel.eval()\n",
    "mymodel.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file 38\n"
     ]
    }
   ],
   "source": [
    "# Load test file data and make predictions\n",
    "from generator import Prepare_Dataset\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from constants import test_data_points\n",
    "\n",
    "list_of_file_ids_test_small = np.random.choice(test_file_ids, size=1, replace=False)\n",
    "test = Prepare_Dataset(file_ids=list_of_file_ids_test_small, points = 10)#test_data_points)\n",
    "print(\"Picked test set ids:\",list_of_file_ids_test_small)\n",
    "print(\"Length of test dataset: \", len(test))\n",
    "\n",
    "test_loader = DataLoader(test, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test, y_test = test[0]\n",
    "\n",
    "# # x_test = x_test.to(device)\n",
    "\n",
    "# x_test = x_test[None, :]\n",
    "# print(x_test.shape)\n",
    "\n",
    "# conv_out = mymodel.forward(x_test)\n",
    "# print(conv_out.repeat(4,1).shape)\n",
    "\n",
    "# m =10000\n",
    "# target_sample, base_sample, target_log_pdf, base_log_pdf = mymodel.pdf.sample(samplesize=m,conditional_input=conv_out.repeat(m,1))#,  device=torch.device(\"cuda:0\")) \n",
    "# print(np.squeeze(target_sample.numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10000\n",
    "x_list=[]\n",
    "y_list=[]\n",
    "shower_energy_log10 = []\n",
    "\n",
    "gauss_fit_sigma_list = []\n",
    "true_energy_prob_list = []\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy import interpolate\n",
    "def gauss(x, *p):\n",
    "    A, mu, sigma = p\n",
    "    return A*(2 * np.pi * sigma)**-0.5 * np.exp(-0.5 * (x - mu) ** 2 * sigma ** -2)\n",
    "    \n",
    "# target_sample_list = np.zeros((1,n))\n",
    "with torch.no_grad():\n",
    "    # Iterate through test set minibatchs \n",
    "    for x, y in tqdm(test_loader):\n",
    "        conv_out = mymodel.forward(x)\n",
    "        target_sample, base_sample, target_log_pdf, base_log_pdf = mymodel.pdf.sample(samplesize=n,conditional_input=conv_out.repeat(n,1))\n",
    "\n",
    "        x_list.append(np.mean(target_sample.numpy()))\n",
    "        y_list.append(np.std(target_sample.numpy()))\n",
    "        shower_energy_log10.append(y.item())\n",
    "        \n",
    "        # find gaussian fit sigma\n",
    "        (count, bins) = np.histogram(target_sample, bins=200)\n",
    "        bins_middle = (bins[:-1] + bins[1:])/2\n",
    "        p0 = [np.max(count), np.mean(target_sample.numpy()), np.std(target_sample.numpy())]\n",
    "        coeff, var_matrix = curve_fit(gauss, bins_middle, count, p0=p0, maxfev = 5000)\n",
    "        \n",
    "        gauss_fit_sigma_list.append(coeff[2]) #sigma fit\n",
    "        \n",
    "        # Coverage\n",
    "        target_pdf = np.exp(target_log_pdf.numpy())\n",
    "        sorted_target_sample = np.sort(np.squeeze(target_sample.numpy()))\n",
    "        index_sorted_target_sample = np.argsort(np.squeeze(target_sample.numpy()))\n",
    "        sorted_target_pdf = target_pdf[index_sorted_target_sample]\n",
    "        \n",
    "#         fig = plt.figure()\n",
    "#         ax = fig.add_subplot(111)\n",
    "#         ax.plot(sorted_target_sample, sorted_target_pdf)\n",
    "        \n",
    "#         coeff2, var_matrix2 = curve_fit(gauss, sorted_target_sample, sorted_target_pdf, p0=p1, maxfev = 5000)\n",
    "#         fitting = gauss(sorted_target_sample, *coeff2)\n",
    "#         ax.plot(sorted_target_sample, fitting, \"k-\",linewidth=2)\n",
    "#         ax.legend([f\"Gaussian fit with \\n$\\mu$ = {coeff2[1]:.2f}\\n$\\sigma$ = {coeff2[2]:.2f}\"], loc='upper right')\n",
    "#         plt.title(f\"Target Probability for {run_name} with E_T = {y.item():.2f}\")\n",
    "#         plt.close()\n",
    "\n",
    "        #CDF\n",
    "        cdf_dx = np.diff(sorted_target_sample)\n",
    "        cdf_x = 0.5*(sorted_target_sample[1:] + sorted_target_sample[:-1])\n",
    "        pdf_y = 0.5*(sorted_target_pdf[1:] + sorted_target_pdf[:-1])\n",
    "        pdf_middle_y = cdf_dx*pdf_y\n",
    "            \n",
    "        cdf_y = np.zeros(len(pdf_middle_y))\n",
    "        for i, pdf_middle_y_i in enumerate(pdf_middle_y):\n",
    "            cdf_y[i] = np.sum(pdf_middle_y[:i])\n",
    "            \n",
    "        cdf = interpolate.interp1d(cdf_x, cdf_y)\n",
    "        true_energy_prob = cdf(y.item())\n",
    "        true_energy_prob_list.append(true_energy_prob)\n",
    "        \n",
    "#         fig = plt.figure()\n",
    "#         ax = fig.add_subplot(111)\n",
    "#         ax.plot(cdf_x, cdf_y, 'k-')\n",
    "#         ax.axvline(x=y.item(), label = f\"ture E = {y.item():.2f}\", linewidth = 2)\n",
    "#         ax.axhline(true_energy_prob, label = f\"ture E = {true_energy_prob:.2f}\", linewidth = 2)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predicted angles\n",
    "shower_energy_log10 = np.array(shower_energy_log10)\n",
    "shower_energy_log10_predict = np.array(x_list)\n",
    "shower_energy_log10_sigma_predict = np.array(y_list)\n",
    "gauss_fit_sigma_list = np.array(gauss_fit_sigma_list)\n",
    "true_energy_prob_list = np.array(true_energy_prob_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_energy_prob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{saved_model_dir}/model.{run_name}.h5_predicted.pkl', \"bw\") as fout:\n",
    "    pickle.dump([shower_energy_log10_predict, shower_energy_log10, shower_energy_log10_sigma_predict, gauss_fit_sigma_list, true_energy_prob_list], fout, protocol=4)\n",
    "\n",
    "print(colored(f\"Done evaluating energy resolution for {run_name}!\", \"green\", attrs=[\"bold\"]))\n",
    "print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
